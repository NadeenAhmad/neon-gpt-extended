import re
import time
from rdflib import Graph
from api_utils import send_prompt, extract_between_markers

def sanitize_turtle_text(turtle_text: str) -> str:
    """Remove non-RDF noise and malformed fragments like ?A :connectedTo ?B ."""
    cleaned_lines = []
    for line in turtle_text.splitlines():
        line = line.strip()
        if not line:
            continue

        # Skip markers, code blocks, or autogenerated comments
        if any(x in line for x in ["###", "```", ":end_turtle", "Turtle block"]):
            continue

        # ðŸ§¹ Remove illegal SPARQL-style variable triples
        if re.search(r"\?[A-Za-z]", line):
            print(f"ðŸª“ Removed SPARQL-like triple: {line}")
            continue

        cleaned_lines.append(line)

    return "\n".join(cleaned_lines)


def clean_prefixes_and_headers(turtle_text: str) -> str:
    """Remove duplicate prefixes and ontology headers."""
    seen_prefixes = set()
    cleaned_lines = []
    for line in turtle_text.splitlines():
        prefix_match = re.match(r'@prefix\s+(\S+):', line)
        if prefix_match:
            prefix = prefix_match.group(1)
            if prefix in seen_prefixes:
                continue
            seen_prefixes.add(prefix)
        if re.search(r'(rdf:type\s+owl:Ontology)', line) and any('Ontology' in l for l in cleaned_lines[-5:]):
            continue
        cleaned_lines.append(line)
    return "\n".join(cleaned_lines)


def llm_fix_turtle_block(problem_block: str, error_message: str) -> str:
    """Ask LLM to fix malformed Turtle syntax."""
    prompt = f"""
You are an expert in RDF and Turtle syntax repair. The following Turtle fragment failed to parse.

Error:
{error_message}

Problematic code:
{problem_block}

Please fix the syntax while preserving its intended semantics.
If you encounter variable-like nodes (?A, ?B, etc.), replace them with proper blank nodes or example IRIs.
Return ONLY valid Turtle triples between the markers.

###start_turtle###
###end_turtle###
"""
    reply = send_prompt(prompt, persona="RDF/Turtle syntax expert", step_name="turtle_repair")
    fixed = extract_between_markers(reply, "###start_turtle###", "###end_turtle###")
    if fixed and fixed[0].strip():
        print("ðŸ¤– LLM proposed fix for malformed Turtle.")
        return fixed[0].strip()
    print("âš ï¸ LLM returned no fix, keeping original block.")
    return problem_block


def find_problematic_block(text: str, error_message: str) -> str:
    match = re.search(r"at line (\d+)", error_message)
    if not match:
        return ""
    line_no = int(match.group(1))
    lines = text.splitlines()
    start = max(0, line_no - 3)
    end = min(len(lines), line_no + 3)
    return "\n".join(lines[start:end])


def deduplicate_triples(turtle_text: str, max_retries: int = 20) -> str:
    """Try parsing ontology; if it fails, use LLM to fix the bad block."""
    g = Graph()
    working_text = turtle_text

    for attempt in range(1, max_retries + 1):
        try:
            g.parse(data=working_text, format="turtle")
            print(f"âœ… Parse succeeded on attempt {attempt}.")
            return g.serialize(format="turtle")
        except Exception as e:
            print(f"âš ï¸ Parse failed (attempt {attempt}): {e}")
            block = find_problematic_block(working_text, str(e))
            if not block.strip():
                print("âš ï¸ Could not isolate problematic section; aborting repair.")
                break
            fixed_block = llm_fix_turtle_block(block, str(e))
            working_text = working_text.replace(block, fixed_block)
            time.sleep(2)

    print("âŒ Could not fully repair ontology after multiple attempts.")
    return working_text


def merge_entities(turtle_text: str) -> str:
    """Merge repeated subject definitions, but skip if parse fails."""
    g = Graph()
    try:
        g.parse(data=turtle_text, format="turtle")
    except Exception as e:
        print("âš ï¸ Skipping merge_entities â€” graph still not fully valid:", e)
        return turtle_text

    merged = Graph()
    for subj in set(g.subjects()):
        for pred, obj in set(g.predicate_objects(subj)):
            merged.add((subj, pred, obj))
    return merged.serialize(format="turtle")


def preprocess_turtle(ontology_text: str) -> str:
    """Full cleaning + LLM-assisted repair pipeline."""
    cleaned = sanitize_turtle_text(ontology_text)
    cleaned = clean_prefixes_and_headers(cleaned)
    cleaned = deduplicate_triples(cleaned)
    cleaned = merge_entities(cleaned)
    return cleaned


def clean_ontology_file(input_path: str, output_path: str):
    print(f"ðŸ“‚ Loading ontology from {input_path}...")
    with open(input_path, "r", encoding="utf-8") as f:
        ontology_text = f.read()

    print("ðŸ§¹ Cleaning ontology (LLM-assisted)...")
    cleaned_text = preprocess_turtle(ontology_text)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(cleaned_text)

    print(f"âœ… Cleaned ontology saved to {output_path}")




input_file = "Wine Ontology_ontology.ttl"
output_file = "Wine Ontology_ontology_cleaned.ttl"
clean_ontology_file(input_file, output_file)
